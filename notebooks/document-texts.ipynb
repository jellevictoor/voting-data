{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b4e1a6-66e7-4ec6-9b7e-e7d27a791e20",
   "metadata": {},
   "source": [
    "# Notebook for analysing document texts\n",
    "\n",
    "This is an analysis of duration and cost of the GPT summarizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae27e03-96aa-4fed-b507-c1a97cc88aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85238c8-cbb4-41b6-b4b0-9cf0c43d753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "!wc -w $(find ../data/output/documents -type f -name \"*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531dbea2-9450-4614-a037-39ead3de5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [l.strip() for l in str(cap).split(\"\\n\")][:-2]\n",
    "lines = [l.split() for l in lines]\n",
    "lines = [(int(a), b) for a,b in lines]\n",
    "lines.sort()\n",
    "print(len(lines))\n",
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df076d-2da4-4834-9124-580151a9f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lines, columns=[\"size\",\"path\"])\n",
    "len(df[df[\"size\"] < 7000]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a686d48-afad-486d-9b9c-fdbe978b49b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(df[\"size\"])\n",
    "plt.ylabel(\"number of words\")\n",
    "plt.xlabel(\"document nr\")\n",
    "plt.title(\"Word counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8df913-c747-4eb7-955f-acb070604b45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "MAX_WORDS=7000\n",
    "plt.plot(df[df[\"size\"] < MAX_WORDS][\"size\"])\n",
    "plt.ylabel(\"number of words\")\n",
    "plt.xlabel(\"document nr\")\n",
    "plt.title(f\"Word counts of documents smaller than {MAX_WORDS} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cc81c-9e28-4aa9-be9c-4eff29bddf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_docs_pct = 100 * len(df[df[\"size\"] < MAX_WORDS]) / len(df)\n",
    "print(f\"{small_docs_pct}% of documents have less then {MAX_WORDS} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca435926-c535-4a75-8d9a-8642522b528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_docs_words_pct = 100 * sum(df[df[\"size\"] < MAX_WORDS][\"size\"]) / sum(df[\"size\"])\n",
    "print(f\"small documents contain {small_docs_words_pct}% of total number of words\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
